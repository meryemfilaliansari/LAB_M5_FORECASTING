# üìä M5 Forecasting - Time Series Analysis with RNN, LSTM & GRU

**Auteur:** FILALI ANSARI Meryem  
**Ann√©e acad√©mique:** 2024-2025  
**Date:** D√©cembre 2025

---

## Table des Mati√®res

1. [Vue d'Ensemble](#vue-densemble)
2. [Objectifs du Projet](#objectifs-du-projet)
3. [Dataset M5 Forecasting](#dataset-m5-forecasting)
4. [Technologies Utilis√©es](#technologies-utilis√©es)
5. [Workflow Complet](#workflow-complet)
6. [Architecture des Mod√®les](#architecture-des-mod√®les)
7. [√âvaluation des Performances](#√©valuation-des-performances)
8. [R√©sultats et Analyses](#r√©sultats-et-analyses)
9. [Am√©liorations Sugg√©r√©es](#am√©liorations-sugg√©r√©es)
10. [Comment Ex√©cuter le Projet](#comment-ex√©cuter-le-projet)
11. [Structure des Fichiers](#structure-des-fichiers)
12. [R√©f√©rences](#r√©f√©rences)

---

## Vue d'Ensemble

Ce projet r√©alise une analyse compl√®te et une pr√©vision des ventes de d√©tail √† partir des donn√©es du concours **M5 Forecasting** en utilisant trois architectures diff√©rentes de R√©seaux de Neurones R√©currents (RNN) :

- **Simple RNN** : Architecture de base pour les s√©quences temporelles
- **LSTM (Long Short-Term Memory)** : Architecture avanc√©e avec m√©canisme de m√©moire
- **GRU (Gated Recurrent Unit)** : Variante optimis√©e du LSTM

Le notebook d√©montre une progression compl√®te depuis l'exploration des donn√©es jusqu'√† la comparaison d√©taill√©e des performances de chaque mod√®le.

---

## Objectifs du Projet

Ce projet a quatre objectifs principaux :

1. **üîç Exploration des Donn√©es** : Comprendre la structure et les tendances g√©n√©rales du dataset M5 Forecasting
2. **üìà Visualisation de l'√âvolution** : Analyser visuellement l'√©volution des ventes dans le temps
3. **ü§ñ Mod√©lisation Pr√©dictive** : Entra√Æner des mod√®les RNN, LSTM et GRU pour pr√©dire les ventes futures
4. **üìä √âvaluation Comparative** : Comparer les performances des trois architectures de r√©seaux r√©currents

---

## Dataset M5 Forecasting

Le projet utilise le dataset officiel du concours **M5 Forecasting - Accuracy** qui comprend :

### üìÅ Fichiers du Dataset

#### 1. **sales_train_evaluation.csv**
- Donn√©es historiques de ventes quotidiennes
- Milliers de produits suivis sur plusieurs ann√©es
- Format : chaque ligne = un produit, chaque colonne = un jour de vente
- Colonnes m√©tadonn√©es : id, item_id, dept_id, cat_id, store_id, state_id

#### 2. **calendar.csv**
- Informations calendaires pour chaque jour
- Dates, jours de la semaine, mois, ann√©es
- √âv√©nements sp√©ciaux et jours f√©ri√©s
- Variables SNAP (Supplemental Nutrition Assistance Program)

#### 3. **sell_prices.csv**
- Historique des prix de vente par produit
- Prix par magasin et par semaine
- Permet d'analyser l'impact des variations de prix sur les ventes

### üìä Caract√©ristiques du Dataset

- **P√©riode couverte** : Plusieurs ann√©es de donn√©es quotidiennes
- **Nombre de produits** : ~30,000 s√©ries temporelles
- **Granularit√©** : Ventes quotidiennes par produit et par magasin
- **Secteur** : Commerce de d√©tail (Walmart)
- **√âtats couverts** : Californie (CA), Texas (TX), Wisconsin (WI)

---

## Technologies Utilis√©es

### üêç Langage et Environnement
- **Python 3.x** : Langage de programmation principal
- **Google Colab** : Environnement de d√©veloppement cloud avec GPU gratuit
- **Jupyter Notebook** : Interface interactive pour l'analyse de donn√©es

### üìö Biblioth√®ques Principales

#### Manipulation de Donn√©es
- **NumPy** : Calculs num√©riques et manipulation de tableaux
- **Pandas** : Analyse et manipulation de donn√©es tabulaires

#### Visualisation
- **Matplotlib** : Cr√©ation de graphiques et visualisations

#### Pr√©traitement
- **Scikit-learn** :
  - `MinMaxScaler` : Normalisation des donn√©es (0-1)
  - `train_test_split` : Division des donn√©es
  - M√©triques : MAE, MSE, RMSE, R¬≤, MAPE

#### Deep Learning
- **TensorFlow/Keras** :
  - `Sequential` : Mod√®le s√©quentiel
  - `SimpleRNN` : Couche RNN basique
  - `LSTM` : Couche Long Short-Term Memory
  - `GRU` : Couche Gated Recurrent Unit
  - `Dense` : Couche de sortie
  - `Adam` : Optimiseur

---

## Workflow Complet

### 1Ô∏è‚É£ Chargement et Exploration Initiale

**√âtape 1 : Montage du Google Drive**
```python
from google.colab import drive
drive.mount('/content/drive')
```

**√âtape 2 : Chargement des donn√©es**
```python
path = '/content/drive/MyDrive/M5_Forecasting/'
sales = pd.read_csv(path + 'sales_train_evaluation.csv')
calendar = pd.read_csv(path + 'calendar.csv')
prices = pd.read_csv(path + 'sell_prices.csv')
```

**√âtape 3 : Exploration de base**
- Affichage des dimensions du dataset
- Aper√ßu des premi√®res lignes
- Statistiques descriptives
- V√©rification des valeurs manquantes

### 2Ô∏è‚É£ Analyse Exploratoire des Donn√©es (EDA)

#### Analyse d'un Produit Individuel
- S√©lection al√©atoire d'un produit
- Visualisation de sa s√©rie temporelle compl√®te
- Identification des tendances et saisonnalit√©s

#### Analyse Agr√©g√©e
- Calcul des ventes totales quotidiennes (tous produits)
- Visualisation de l'√©volution globale
- Calcul des statistiques : moyenne, max, min

#### Analyse Comparative
- Visualisation de 3 s√©ries temporelles al√©atoires
- Identification de patterns diff√©rents entre produits
- Compr√©hension de la variabilit√© des ventes

### 3Ô∏è‚É£ Pr√©traitement des Donn√©es

#### S√©lection et Extraction
```python
# Extraction des 1000 derniers jours d'un produit
data = ts[-1000:].values.reshape(-1, 1)
```

#### Normalisation
```python
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)
# Normalisation entre 0 et 1
```

#### Cr√©ation de S√©quences
```python
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

SEQ_LEN = 30  # Fen√™tre de 30 jours
X, y = create_sequences(data_scaled, SEQ_LEN)
```

#### Division Train/Test
```python
split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]
```

**Dimensions finales :**
- `X_train` : (nombre_sequences_train, 30, 1)
- `y_train` : (nombre_sequences_train, 1)
- `X_test` : (nombre_sequences_test, 30, 1)
- `y_test` : (nombre_sequences_test, 1)

---

## Architecture des Mod√®les

### üî∑ Configuration Commune

Tous les mod√®les partagent la m√™me structure de base :

```python
model = Sequential()
model.add([RNN_LAYER](50, activation='tanh', input_shape=(30, 1)))
model.add(Dense(1))
model.compile(optimizer=Adam(learning_rate=0.001), 
              loss='mse', 
              metrics=['mae'])
```

**Param√®tres d'entra√Ænement :**
- **Epochs** : 30
- **Batch Size** : 32
- **Optimizer** : Adam (learning_rate=0.001)
- **Loss Function** : Mean Squared Error (MSE)
- **Metric** : Mean Absolute Error (MAE)
- **Validation Data** : X_test, y_test

### üîπ Simple RNN

**Architecture :**
```python
model.add(SimpleRNN(50, activation='tanh', input_shape=(SEQ_LEN, 1)))
```

**Caract√©ristiques :**
- **Type** : R√©seau de neurones r√©current basique
- **Unit√©s** : 50 neurones
- **Activation** : tanh (tangente hyperbolique)
- **Avantages** : Simple, rapide √† entra√Æner
- **Limitations** : Probl√®me du gradient qui dispara√Æt sur longues s√©quences

**Param√®tres totaux** : ~2,601

### üî∏ LSTM (Long Short-Term Memory)

**Architecture :**
```python
model.add(LSTM(50, activation='tanh', input_shape=(SEQ_LEN, 1)))
```

**Caract√©ristiques :**
- **Type** : R√©seau r√©current avec m√©canisme de m√©moire
- **Unit√©s** : 50 cellules LSTM
- **Activation** : tanh
- **Composants** :
  - Input Gate : Contr√¥le l'entr√©e de nouvelles informations
  - Forget Gate : D√©cide quelles informations oublier
  - Output Gate : Contr√¥le la sortie
  - Cell State : M√©moire √† long terme

**Avantages** :
- G√®re mieux les d√©pendances √† long terme
- R√©siste au probl√®me du gradient qui dispara√Æt
- Meilleure performance sur s√©quences longues

**Param√®tres totaux** : ~10,401

### üî∂ GRU (Gated Recurrent Unit)

**Architecture :**
```python
model.add(GRU(50, activation='tanh', input_shape=(SEQ_LEN, 1)))
```

**Caract√©ristiques :**
- **Type** : Variante optimis√©e du LSTM
- **Unit√©s** : 50 cellules GRU
- **Activation** : tanh
- **Composants** :
  - Update Gate : Combine input et forget gates du LSTM
  - Reset Gate : Contr√¥le l'oubli d'informations pass√©es

**Avantages** :
- Moins de param√®tres que LSTM
- Entra√Ænement plus rapide
- Performance souvent comparable au LSTM
- Architecture simplifi√©e

**Param√®tres totaux** : ~7,851

---

## √âvaluation des Performances

### üìä M√©triques Calcul√©es

Le notebook calcule plusieurs m√©triques pour une √©valuation compl√®te :

#### 1. **MAE (Mean Absolute Error)**
```
Erreur absolue moyenne entre pr√©dictions et valeurs r√©elles
Plus la valeur est proche de 0, meilleur est le mod√®le
Formule : (1/n) √ó Œ£|y_true - y_pred|
```

#### 2. **MSE (Mean Squared Error)**
```
Moyenne des erreurs au carr√©
P√©nalise davantage les grandes erreurs
Formule : (1/n) √ó Œ£(y_true - y_pred)¬≤
```

#### 3. **RMSE (Root Mean Squared Error)**
```
Racine carr√©e du MSE
M√™me unit√© que les donn√©es originales
Formule : ‚àöMSE
```

#### 4. **R¬≤ Score (Coefficient de D√©termination)**
```
Mesure la qualit√© de l'ajustement (0 √† 1)
1.0 = pr√©diction parfaite
0.0 = mod√®le aussi bon qu'une moyenne
Valeurs n√©gatives = mod√®le moins bon qu'une moyenne
```

#### 5. **MAPE (Mean Absolute Percentage Error)**
```
Erreur en pourcentage
Facile √† interpr√©ter
Formule : (1/n) √ó Œ£|(y_true - y_pred) / y_true| √ó 100
```

### üìà Visualisations G√©n√©r√©es

#### 1. **Courbes d'Apprentissage**
- **MAE Training & Validation** : √âvolution de l'erreur pendant l'entra√Ænement
- **Loss (MSE) Training & Validation** : √âvolution de la fonction de perte
- Permet d'identifier le surapprentissage (overfitting)

#### 2. **Pr√©dictions vs. Valeurs R√©elles**
- Graphiques comparant les 100 premi√®res pr√©dictions
- Trois sous-graphiques (un par mod√®le)
- L√©gendes avec MAE de chaque mod√®le

#### 3. **Analyse des R√©sidus**
- **R√©sidus vs. Pr√©dictions** : Scatter plot pour d√©tecter les biais
- **Distribution des R√©sidus** : Histogrammes pour v√©rifier la normalit√©
- Aide √† identifier les patterns d'erreurs

#### 4. **Comparaison par M√©triques**
- Graphiques en barres pour chaque m√©trique
- Comparaison visuelle des 3 mod√®les
- Valeurs num√©riques affich√©es sur les barres



## R√©sultats et Analyses

### üìã R√©sum√© des Performances Typiques

Les mod√®les RNN produisent g√©n√©ralement les r√©sultats suivants sur les donn√©es M5 :

**Ordre de Performance (du meilleur au moins bon) :**
1. **LSTM** : Meilleure performance gr√¢ce √† sa m√©moire √† long terme
2. **GRU** : Performance proche du LSTM avec moins de param√®tres
3. **Simple RNN** : Performance acceptable mais limit√©e sur longues s√©quences

### üîç Analyse D√©taill√©e

#### Architecture des Mod√®les
- **Simple RNN** : ~2,601 param√®tres
- **GRU** : ~7,851 param√®tres
- **LSTM** : ~10,401 param√®tres

#### Temps d'Entra√Ænement
- **Simple RNN** : Le plus rapide (architecture simple)
- **GRU** : Temps interm√©diaire
- **LSTM** : Le plus lent (architecture complexe)

#### Capacit√© de G√©n√©ralisation
- **LSTM** : Meilleure capacit√© √† capturer les d√©pendances √† long terme
- **GRU** : Bon compromis performance/complexit√©
- **Simple RNN** : Difficult√© avec les d√©pendances longues

### üìä Analyse des R√©sidus

L'analyse des r√©sidus r√©v√®le :
- **Distribution** : Id√©alement centr√©e autour de z√©ro
- **Patterns** : Absence de patterns indique un bon mod√®le
- **Outliers** : Identification des pr√©dictions probl√©matiques

---

## Am√©liorations Sugg√©r√©es

Le notebook propose 10 am√©liorations pour optimiser les performances :

### üîß 1. Augmenter le Nombre de Neurones
- **Actuel** : 50 unit√©s
- **Suggestion** : Tester 100, 128, 256 unit√©s
- **Impact** : Augmente la capacit√© du mod√®le

### üîß 2. Ajouter des Couches R√©currentes Suppl√©mentaires
- Architecture plus profonde avec plusieurs couches LSTM/GRU
- **Impact** : Meilleure extraction de features

### üîß 3. Tester Diff√©rentes Longueurs de S√©quences
```
Taille du filtre de convolution
Format : (height, width)
Exemple : (3, 3) = filtre de 3√ó3 pixels
```

#### 4. STRIDES (strides)
```
Pas de d√©placement du filtre
Format : (vertical_stride, horizontal_stride)
Exemple : (2, 2) = le filtre saute 2 pixels √† chaque fois
```

#### 5. PADDING (padding)
```
'valid' : pas de padding ‚Üí taille r√©duite
'same'  : padding ajout√© ‚Üí conserve la m√™me taille (avec stride=1)
```

#### 6. ACTIVATION (activation)
```
Fonction d'activation apr√®s convolution
None = pas d'activation (convolution pure)
Autres : 'relu', 'sigmoid', 'tanh', etc.
```

#### 7. USE_BIAS (use_bias)
```
True = ajoute un biais b √† chaque filtre
Formule : output = conv(input, weights) + bias
```

### Calcul de la Taille de Sortie

**Formule math√©matique :**

```
Output_size = ((Input_size - Kernel_size + 2√óPadding) / Stride) + 1
```

**Application √† notre exemple :**

```
Input : 5√ó5√ó3
Kernel : 3√ó3√ó3
Stride : 2
Padding : same (= 1)
Filters : 2

Calcul hauteur :
Output_height = ((5 - 3 + 2√ó1) / 2) + 1 = ((5 - 3 + 2) / 2) + 1 = (4/2) + 1 = 3

Calcul largeur :
Output_width = ((5 - 3 + 2√ó1) / 2) + 1 = 3

R√©sultat : Sortie = 3√ó3√ó2
```

### Extraction et Visualisation des Poids

**Dimensions des poids (kernels) :**
```
Shape : (3, 3, 3, 2)
- Taille du filtre : 3√ó3
- Canaux d'entr√©e : 3 (RGB)
- Nombre de filtres : 2
```

**Dimensions des biais :**
```
Shape : (2,)
- Un biais par filtre
```

### Processus de Convolution D√©taill√©

Le laboratoire d√©montre le processus complet avec stride=2 :

**Positions de calcul (avec stride=2) :**
1. Position [0,0] : Coin sup√©rieur gauche
2. Position [0,2] : D√©placement horizontal de 2 pixels
3. Position [2,0] : D√©placement vertical de 2 pixels
4. Position [2,2] : Coin inf√©rieur droit accessible

**Calcul √† chaque position :**

```python
Pour chaque position (y, x):
    1. Extraire r√©gion 3√ó3√ó3 de l'input
    2. Pour chaque canal c (0, 1, 2):
        conv_result += somme(r√©gion[:,:,c] * filtre[:,:,c])
    3. Ajouter le biais: conv_result += bias
    4. Placer le r√©sultat dans feature_map[y//2, x//2]
```

**Formule math√©matique de la convolution :**

```
Feature_Map[i,j] = Œ£ Œ£ Œ£ (Input[i*s + m, j*s + n, c] √ó Kernel[m, n, c]) + Bias
                   m n c

o√π:
- i, j : indices dans la feature map
- s : stride (2 dans notre cas)
- m, n : indices dans le kernel (0, 1, 2)
- c : indice du canal (0, 1, 2)
```

### Visualisations G√©n√©r√©es

Le laboratoire 1 produit plusieurs visualisations p√©dagogiques :

#### 1. Input Volume (4 graphiques)
- Canal 1 (Red) : Heatmap 5√ó5
- Canal 2 (Green) : Heatmap 5√ó5
- Canal 3 (Blue) : Heatmap 5√ó5
- Vue RGB combin√©e : Visualisation couleur

#### 2. Filtres de Convolution
- Filtre W0 - 3 canaux : 3 heatmaps 3√ó3 + biais
- Filtre W1 - 3 canaux : 3 heatmaps 3√ó3 + biais
- Valeurs des poids affich√©es avec 2 d√©cimales
- Colormap divergente (RdBu_r) centr√©e sur 0

#### 3. Feature Maps de Sortie
- Feature Map 0 : R√©sultat du filtre W0 (3√ó3)
- Feature Map 1 : R√©sultat du filtre W1 (3√ó3)
- Statistiques : Min, Max, Mean pour chaque feature map
- Colormap viridis pour visualisation

#### 4. Processus Complet de Convolution
- Grille 3√ó6 montrant toutes les √©tapes
- Ligne 1 : Input (3 canaux) + Filtre W0 (3 canaux)
- Ligne 2 : 4 positions de convolution avec stride=2
- Ligne 3 : Feature maps finales (2 filtres)
- Calculs manuels affich√©s pour chaque position

### Points Cl√©s du Laboratoire 1

**Compr√©hension profonde :**
- Calcul manuel de chaque convolution
- Visualisation des poids et des feature maps
- Impact du stride sur la taille de sortie
- R√¥le du padding dans la conservation des dimensions

**Formules essentielles :**
- Taille de sortie en fonction des param√®tres
- Nombre de param√®tres : (kernel_h √ó kernel_w √ó in_channels + 1) √ó n_filters
- Dans notre cas : (3 √ó 3 √ó 3 + 1) √ó 2 = 56 param√®tres

**Observations :**
- Stride=2 r√©duit les dimensions de sortie de moiti√©
- Padding='same' avec stride=1 conserverait les dimensions
- Chaque filtre apprend √† d√©tecter une caract√©ristique diff√©rente
- Les biais permettent de d√©caler les activations

---

## Laboratoire 2 : CNN Appliqu√©s et D√©tection de Contours

### Objectif

Appliquer les concepts de convolution √† des cas pratiques de traitement d'image :
- Comprendre les filtres de d√©tection de contours
- Impl√©menter des filtres classiques (Sobel, Prewitt, etc.)
- Appliquer les convolutions sur des images r√©elles
- Analyser les r√©sultats visuellement

### Introduction aux CNN (Contexte Th√©orique)

Le laboratoire 2 commence par une introduction compl√®te aux CNN :

#### Pourquoi les CNN ?

**Probl√®mes des r√©seaux enti√®rement connect√©s :**
- Nombre √©lev√© de param√®tres pour les images
- Perte de l'information spatiale locale
- Pas d'exploitation des relations entre pixels voisins

**Solutions apport√©es par les CNN :**
- R√©duction du nombre de param√®tres par partage des poids
- Pr√©servation de l'information spatiale locale
- Capture des caract√©ristiques hi√©rarchiques

#### Principe de Base des Convolutions

Une convolution consiste √† :
1. Appliquer un filtre (noyau) sur une image
2. Glisser le filtre sur toute l'image
3. Effectuer produit √©l√©ment par √©l√©ment + somme √† chaque position
4. Cr√©er une nouvelle image (feature map) avec les r√©sultats

### Dataset et Images

**Image Synth√©tique Simple (5√ó5) :**

```python
image = np.array([
    [1, 2, 3, 4, 5],
    [5, 6, 7, 8, 9],
    [9, 8, 7, 6, 5],
    [5, 4, 3, 2, 1],
    [1, 2, 3, 4, 5]
], dtype=np.float32)
```

**Image R√©elle :**
- Charg√©e depuis Google Drive
- Convertie en niveaux de gris
- Format PIL ‚Üí NumPy ‚Üí TensorFlow
- Chemin : '/content/drive/MyDrive/.../maison2.jpg'

### Filtres de D√©tection de Contours

#### 1. Filtre de D√©tection de Bords Horizontaux

**D√©finition du filtre :**

```python
kernel_horizontal = np.array([
    [-1, -1, -1],
    [ 0,  0,  0],
    [ 1,  1,  1]
], dtype=np.float32)
```

**Principe :**
- Ligne sup√©rieure : poids n√©gatifs (-1)
- Ligne centrale : poids nuls (0)
- Ligne inf√©rieure : poids positifs (+1)

**Effet :**
- D√©tecte les transitions de clair √† fonc√© (haut ‚Üí bas)
- R√©ponse forte aux bords horizontaux
- Valeurs √©lev√©es = changement significatif

#### 2. Filtre de D√©tection de Bords Verticaux

```python
kernel_vertical = np.array([
    [-1, 0, 1],
    [-1, 0, 1],
    [-1, 0, 1]
], dtype=np.float32)
```

**Principe :**
- Colonne gauche : poids n√©gatifs
- Colonne centrale : poids nuls
- Colonne droite : poids positifs

**Effet :**
- D√©tecte les transitions de gauche √† droite
- R√©ponse forte aux bords verticaux

#### 3. Filtre Sobel Horizontal

```python
kernel_sobel_h = np.array([
    [-1, -2, -1],
    [ 0,  0,  0],
    [ 1,  2,  1]
], dtype=np.float32)
```

**Caract√©ristiques :**
- Version am√©lior√©e du filtre horizontal
- Poids centraux doubl√©s (-2, +2)
- Plus sensible aux bords au centre
- R√©duit le bruit en lissant

#### 4. Filtre Sobel Vertical

```python
kernel_sobel_v = np.array([
    [-1, 0, 1],
    [-2, 0, 2],
    [-1, 0, 1]
], dtype=np.float32)
```

#### 5. Filtre Prewitt

**Horizontal :**
```python
kernel_prewitt_h = np.array([
    [-1, -1, -1],
    [ 0,  0,  0],
    [ 1,  1,  1]
], dtype=np.float32)
```

**Vertical :**
```python
kernel_prewitt_v = np.array([
    [-1, 0, 1],
    [-1, 0, 1],
    [-1, 0, 1]
], dtype=np.float32)
```

#### 6. Filtre Laplacien

```python
kernel_laplacian = np.array([
    [ 0, -1,  0],
    [-1,  4, -1],
    [ 0, -1,  0]
], dtype=np.float32)
```

**Principe :**
- D√©riv√©e seconde
- D√©tecte tous les contours (toutes directions)
- Sensible au bruit
- Valeur centrale positive, voisins n√©gatifs

### Application des Filtres avec TensorFlow

**Code g√©n√©ral d'application :**

```python
# Reshape de l'image
image_tf = image.reshape((1, H, W, 1))

# Reshape du filtre
kernel_tf = kernel.reshape((3, 3, 1, 1))

# Application de la convolution
convolved = tf.nn.conv2d(
    image_tf, 
    kernel_tf, 
    strides=[1, 1, 1, 1],  # Stride de 1
    padding='VALID'         # Pas de padding
)

# Extraction du r√©sultat
result = convolved.numpy().squeeze()
```

**Param√®tres de tf.nn.conv2d :**
- **input** : Image au format [batch, height, width, channels]
- **filter** : Filtre au format [height, width, in_channels, out_channels]
- **strides** : [1, stride_h, stride_w, 1]
- **padding** : 'VALID' (sans padding) ou 'SAME' (avec padding)

### Calcul de la Taille de Sortie

**Avec padding='VALID' :**

```
Output_height = Input_height - Kernel_height + 1
Output_width = Input_width - Kernel_width + 1

Exemple avec image 5√ó5 et kernel 3√ó3 :
Output_height = 5 - 3 + 1 = 3
Output_width = 5 - 3 + 1 = 3
Sortie = 3√ó3
```

**Avec padding='SAME' :**

```
Output_height = ‚åàInput_height / Stride‚åâ
Output_width = ‚åàInput_width / Stride‚åâ

Exemple avec stride=1 :
Output conserve la m√™me taille que l'input
```

### Visualisations G√©n√©r√©es

Le laboratoire 2 produit plusieurs types de visualisations :

#### 1. Image Originale
- Affichage en niveaux de gris
- Colormap 'gray'
- Sans axes pour meilleure lisibilit√©

#### 2. Filtres (Kernels)
- Heatmap 3√ó3 de chaque filtre
- Valeurs annot√©es
- Colormap 'gray' ou divergente

#### 3. Images Convolutionn√©es
- R√©sultat de chaque filtre appliqu√©
- Comparaison c√¥te √† c√¥te
- Mise en √©vidence des contours d√©tect√©s

#### 4. Comparaisons Multiples
- Grid de sous-graphiques
- Image originale vs r√©sultats de diff√©rents filtres
- Analyse comparative des d√©tections

### Application sur Image R√©elle

**√âtapes du traitement :**

1. **Chargement** : 
   ```python
   img = Image.open(chemin_image).convert('L')
   image_real = np.array(img, dtype=np.float32)
   ```

2. **Pr√©paration** :
   ```python
   image_tf = image_real.reshape((1, H, W, 1))
   ```

3. **Application des filtres** :
   - Horizontal edges
   - Vertical edges
   - Sobel (H et V)
   - Prewitt (H et V)
   - Laplacian

4. **Visualisation des r√©sultats** :
   - Grid 2√ó4 ou 3√ó3
   - Original + 7 filtres diff√©rents
   - Analyse comparative

### Analyse des R√©sultats

**Observations typiques :**

1. **Filtre Horizontal** :
   - D√©tecte toits, fondations
   - Lignes horizontales accentu√©es
   - Transitions haut-bas

2. **Filtre Vertical** :
   - D√©tecte murs, colonnes
   - Lignes verticales accentu√©es
   - Transitions gauche-droite

3. **Sobel** :
   - D√©tection plus robuste
   - Moins de bruit que les filtres simples
   - Contours plus nets

4. **Prewitt** :
   - Similaire √† Sobel
   - L√©g√®rement moins de lissage
   - Sensibilit√© diff√©rente

5. **Laplacien** :
   - D√©tecte tous les contours
   - Plus sensible au bruit
   - Contours plus fins

### Comparaison des Filtres

| Filtre | Type | Directionnalit√© | Robustesse au Bruit | Usage |
|--------|------|-----------------|---------------------|-------|
| Horizontal Simple | Gradient | Horizontal uniquement | Faible | P√©dagogique |
| Vertical Simple | Gradient | Vertical uniquement | Faible | P√©dagogique |
| Sobel H | Gradient | Horizontal | Moyenne | Production |
| Sobel V | Gradient | Vertical | Moyenne | Production |
| Prewitt H | Gradient | Horizontal | Faible | Comparaison |
| Prewitt V | Gradient | Vertical | Faible | Comparaison |
| Laplacien | D√©riv√©e 2nd | Toutes directions | Tr√®s faible | D√©tection fine |

### Points Cl√©s du Laboratoire 2

**Applications pratiques :**
- D√©tection de contours dans images r√©elles
- Pr√©traitement pour vision par ordinateur
- Extraction de caract√©ristiques

**Concepts importants :**
- Diff√©rents types de filtres pour diff√©rentes d√©tections
- Impact du padding sur la taille de sortie
- Trade-off sensibilit√© vs robustesse au bruit

**Comp√©tences acquises :**
- Utilisation de tf.nn.conv2d
- Manipulation d'images avec PIL et NumPy
- Visualisation comparative avec Matplotlib
- Analyse qualitative des r√©sultats

---

## D√©pendances et Installation

### Requirements

```
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
tensorflow>=2.8.0
Pillow>=8.0.0
```

### Installation

**M√©thode 1 : pip**

```bash
pip install numpy matplotlib seaborn tensorflow pillow
```

**M√©thode 2 : conda**

```bash
conda install numpy matplotlib seaborn tensorflow pillow
```

**M√©thode 3 : requirements.txt**

```bash
pip install -r requirements.txt
```

### V√©rification de l'Installation

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from PIL import Image

print(f"NumPy version: {np.__version__}")
print(f"Matplotlib version: {matplotlib.__version__}")
print(f"Seaborn version: {sns.__version__}")
print(f"TensorFlow version: {tf.__version__}")
print(f"Pillow version: {Image.__version__}")
```

### Configuration Google Colab

Pour le laboratoire 2 (acc√®s Google Drive) :

```python
from google.colab import drive
drive.mount('/content/drive')
```

### Environnement Recommand√©

- **Python** : 3.8 ou sup√©rieur
- **RAM** : Minimum 4 GB (8 GB recommand√©)
- **GPU** : Non requis (CPU suffisant)
- **Syst√®me** : Windows 10/11, Linux, macOS
- **IDE** : Jupyter Notebook, JupyterLab, VS Code, Google Colab

---

## Concepts Th√©oriques

### Convolution 2D

**D√©finition math√©matique :**

```
(I * K)[i, j] = Œ£ Œ£ I[i + m, j + n] √ó K[m, n]
                m n
```

o√π :
- I : Image d'entr√©e
- K : Kernel (filtre)
- [i, j] : Position dans l'image de sortie
- [m, n] : Position dans le kernel

**Propri√©t√©s :**
- Commutativit√© : I * K = K * I
- Associativit√© : (I * K‚ÇÅ) * K‚ÇÇ = I * (K‚ÇÅ * K‚ÇÇ)
- Distributivit√© : I * (K‚ÇÅ + K‚ÇÇ) = I * K‚ÇÅ + I * K‚ÇÇ
- Lin√©arit√© : a(I * K) = (aI) * K = I * (aK)

### Stride et Padding

**Stride (s) :**
- Pas de d√©placement du filtre
- Stride grand ‚Üí Output petit
- Stride=1 : d√©placement pixel par pixel
- Stride=2 : d√©placement tous les 2 pixels

**Padding (p) :**
- Ajout de pixels aux bords de l'image
- Padding=0 ('VALID') : pas d'ajout
- Padding='SAME' : ajout pour conserver la taille
- Calcul du padding : p = (K - 1) / 2 pour stride=1

**Formule g√©n√©rale de la taille de sortie :**

```
O = ‚åä(I - K + 2p) / s‚åã + 1

o√π :
- O : Taille de l'output
- I : Taille de l'input
- K : Taille du kernel
- p : Padding
- s : Stride
- ‚åä‚åã : Partie enti√®re (floor)
```

### Nombre de Param√®tres

**Pour une couche de convolution :**

```
Param√®tres = (K_h √ó K_w √ó C_in + 1) √ó C_out

o√π :
- K_h, K_w : Dimensions du kernel
- C_in : Nombre de canaux d'entr√©e
- C_out : Nombre de filtres (canaux de sortie)
- +1 : Pour le biais (si use_bias=True)
```

**Exemple du Lab 1 :**
```
Param√®tres = (3 √ó 3 √ó 3 + 1) √ó 2 = 28 √ó 2 = 56 param√®tres
- Poids : 54
- Biais : 2
```

### Feature Maps

**D√©finition :**
- R√©sultat de l'application d'un filtre sur l'input
- Chaque filtre produit une feature map
- Les feature maps capturent diff√©rentes caract√©ristiques

**Hi√©rarchie des features :**
- Couches basses : Contours, textures simples
- Couches moyennes : Motifs, formes
- Couches hautes : Objets complexes, concepts

### D√©tection de Contours

**Gradient d'image :**

Le gradient mesure le taux de changement de l'intensit√© des pixels.

```
‚àáI = (‚àÇI/‚àÇx, ‚àÇI/‚àÇy)

Magnitude : |‚àáI| = ‚àö((‚àÇI/‚àÇx)¬≤ + (‚àÇI/‚àÇy)¬≤)
Direction : Œ∏ = arctan(‚àÇI/‚àÇy / ‚àÇI/‚àÇx)
```

**Op√©rateurs de gradient :**

1. **Sobel** :
   - Approximation du gradient par convolution
   - Lissage int√©gr√© (poids 1-2-1)
   - Plus robuste au bruit

2. **Prewitt** :
   - Similaire √† Sobel
   - Poids uniformes (1-1-1)
   - Plus simple math√©matiquement

3. **Laplacien** :
   - D√©riv√©e seconde
   - D√©tecte changements de gradient
   - Sensible au bruit

### Pourquoi les CNN Fonctionnent Bien

**1. Partage des Poids (Weight Sharing) :**
- M√™me filtre appliqu√© partout
- R√©duit drastiquement le nombre de param√®tres
- Invariance par translation

**2. Connexions Locales :**
- Chaque neurone connect√© √† r√©gion locale
- Exploite corr√©lation spatiale
- Champ r√©cepteur (receptive field)

**3. Hi√©rarchie de Features :**
- Caract√©ristiques simples ‚Üí complexes
- Composition de features
- Repr√©sentations abstraites

**4. R√©duction Dimensionnelle :**
- Stride > 1 r√©duit la taille
- Pooling (non utilis√© dans les labs)
- Compression progressive de l'information

---

## Structure des Fichiers

```
mssror/
‚îú‚îÄ‚îÄ CNN_LAB1.ipynb                    # Lab 1 : CNN Fondamentaux
‚îú‚îÄ‚îÄ CNN_LAB2.ipynb                    # Lab 2 : D√©tection de Contours
‚îú‚îÄ‚îÄ README.md                         # Ce fichier
‚îú‚îÄ‚îÄ .git/                             # Version control
‚îî‚îÄ‚îÄ images/                           # (optionnel) Images de test
    ‚îî‚îÄ‚îÄ maison2.jpg                   # Image exemple pour Lab 2
```

---

## Ex√©cution des Notebooks

### Jupyter Notebook

```bash
cd C:\Users\awati\Desktop\mssror
jupyter notebook
```

Puis ouvrir :
- `CNN_LAB1.ipynb`
- `CNN_LAB2.ipynb`

### VS Code

1. Ouvrir VS Code dans le r√©pertoire
2. Installer l'extension Python et Jupyter
3. Ouvrir le fichier .ipynb
4. S√©lectionner le kernel Python appropri√©
5. Ex√©cuter les cellules s√©quentiellement

### Google Colab

1. Aller sur [colab.research.google.com](https://colab.research.google.com)
2. File ‚Üí Upload notebook
3. S√©lectionner le fichier .ipynb
4. Pour Lab 2 : Monter Google Drive pour acc√©der aux images
5. Ex√©cuter les cellules

---

## Applications Pratiques des CNN

### Vision par Ordinateur

**Classification d'images :**
- Reconnaissance d'objets (ImageNet)
- Classification m√©dicale (radiographies)
- Identification de produits

**D√©tection d'objets :**
- YOLO (You Only Look Once)
- R-CNN, Fast R-CNN, Faster R-CNN
- SSD (Single Shot Detector)

**Segmentation d'images :**
- U-Net (segmentation biom√©dicale)
- Mask R-CNN
- DeepLab

### Traitement d'Images

**Am√©lioration d'images :**
- Super-r√©solution
- D√©bruitage
- Colorisation

**Style Transfer :**
- Transfert de style artistique
- Neural Style Transfer
- CycleGAN

### Applications Industrielles

**Inspection Qualit√© :**
- D√©tection de d√©fauts
- Contr√¥le automatique
- Tri automatique

**V√©hicules Autonomes :**
- D√©tection de pi√©tons
- Reconnaissance de panneaux
- Segmentation de la route

**S√©curit√© :**
- Reconnaissance faciale
- D√©tection d'intrusion
- Surveillance vid√©o

---

## Extensions Possibles

### Pour le Laboratoire 1

1. **Autres configurations** :
   - Tester stride=1, stride=3
   - Comparer padding='valid' vs 'same'
   - Augmenter le nombre de filtres

2. **Ajout d'activations** :
   - ReLU apr√®s convolution
   - Sigmoid, Tanh
   - Leaky ReLU, ELU

3. **Couches suppl√©mentaires** :
   - MaxPooling2D
   - Plusieurs couches Conv2D
   - Batch Normalization

4. **Visualisations avanc√©es** :
   - Animation du processus
   - Visualisation 3D
   - Champs r√©cepteurs

### Pour le Laboratoire 2

1. **Filtres additionnels** :
   - Roberts Cross
   - Scharr
   - Canny edge detector complet

2. **Combinaisons de filtres** :
   - Gradient magnitude : ‚àö(Gx¬≤ + Gy¬≤)
   - Direction du gradient : arctan(Gy/Gx)
   - Non-maximum suppression

3. **Applications avanc√©es** :
   - D√©tection de coins (Harris)
   - Extraction de features SIFT
   - HOG (Histogram of Oriented Gradients)

4. **Dataset r√©el** :
   - CIFAR-10, CIFAR-100
   - MNIST, Fashion-MNIST
   - ImageNet

---

## R√©sultats et Conclusions

### Laboratoire 1

**R√©sultats cl√©s :**
- Compr√©hension du calcul de convolution
- Visualisation des poids et feature maps
- Impact mesurable du stride et du padding
- Feature maps de dimension 3√ó3√ó2 g√©n√©r√©es avec succ√®s

**Conclusion :** Le laboratoire 1 d√©montre que la convolution est une op√©ration math√©matique simple mais puissante. Le partage des poids permet de r√©duire drastiquement le nombre de param√®tres tout en capturant efficacement les caract√©ristiques spatiales.

**Validation :**
- Calculs manuels correspondent aux r√©sultats TensorFlow
- Feature maps coh√©rentes avec l'input et les filtres
- Formules de dimensionnement v√©rifi√©es

### Laboratoire 2

**R√©sultats cl√©s :**
- D√©tection effective des contours horizontaux et verticaux
- Sobel plus robuste que les filtres simples
- Laplacien d√©tecte tous les contours mais sensible au bruit
- Application r√©ussie sur image r√©elle (maison)

**Conclusion :** Le laboratoire 2 illustre l'application pratique des CNN pour le traitement d'images. Les diff√©rents filtres r√©v√®lent diff√©rentes caract√©ristiques de l'image, base essentielle pour des t√¢ches de vision par ordinateur plus complexes.

**Observations :**
- Choix du filtre d√©pend de l'application
- Preprocessing (normalisation) am√©liore les r√©sultats
- Combinaison de filtres donne informations compl√©mentaires

---

## Perspectives et D√©veloppements Futurs

### Court Terme

1. **Architectures classiques** :
   - LeNet-5 (reconnaissance de chiffres)
   - AlexNet (ImageNet 2012)
   - VGGNet (couches tr√®s profondes)

2. **Techniques modernes** :
   - ResNet (connexions r√©siduelles)
   - Inception (filtres multi-√©chelles)
   - MobileNet (efficacit√© mobile)

### Moyen Terme

1. **Transfer Learning** :
   - Utilisation de mod√®les pr√©-entra√Æn√©s
   - Fine-tuning pour t√¢ches sp√©cifiques
   - Feature extraction

2. **Data Augmentation** :
   - Rotation, flip, zoom
   - Color jittering
   - Mixup, CutMix

### Long Terme

1. **Architectures avanc√©es** :
   - Vision Transformers
   - EfficientNet
   - Neural Architecture Search

2. **Applications √©mergentes** :
   - Deepfakes
   - GANs pour g√©n√©ration d'images
   - Few-shot learning

---

## R√©f√©rences

### Livres

1. **Deep Learning with Python** (2nd Edition)  
   Fran√ßois Chollet (2021)  
   Manning Publications

2. **Deep Learning**  
   Ian Goodfellow, Yoshua Bengio, Aaron Courville (2016)  
   MIT Press

3. **Computer Vision: Algorithms and Applications** (2nd Edition)  
   Richard Szeliski (2022)  
   Springer

### Articles Fondateurs

1. **Gradient-Based Learning Applied to Document Recognition**  
   Y. LeCun, L. Bottou, Y. Bengio, P. Haffner (1998)  
   Proceedings of the IEEE  
   (LeNet-5)

2. **ImageNet Classification with Deep Convolutional Neural Networks**  
   Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton (2012)  
   NeurIPS  
   (AlexNet)

3. **Very Deep Convolutional Networks for Large-Scale Image Recognition**  
   Karen Simonyan, Andrew Zisserman (2014)  
   ICLR  
   (VGGNet)

4. **Deep Residual Learning for Image Recognition**  
   Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun (2015)  
   CVPR  
   (ResNet)

### Documentation en Ligne

- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)
- [Keras Documentation](https://keras.io/api/)
- [NumPy Documentation](https://numpy.org/doc/)
- [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)
- [Pillow Documentation](https://pillow.readthedocs.io/)

### Tutoriels et Cours

- [TensorFlow Tutorials - Convolutional Neural Networks](https://www.tensorflow.org/tutorials/images/cnn)
- [CS231n: Convolutional Neural Networks for Visual Recognition - Stanford](http://cs231n.stanford.edu/)
- [Deep Learning Specialization - Coursera](https://www.coursera.org/specializations/deep-learning)
- [Fast.ai Practical Deep Learning](https://course.fast.ai/)

### Datasets Populaires

- **MNIST** : Chiffres manuscrits (28√ó28, 10 classes)
- **CIFAR-10** : Objets naturels (32√ó32, 10 classes)
- **CIFAR-100** : Objets naturels (32√ó32, 100 classes)
- **ImageNet** : 1.4M images, 1000 classes
- **COCO** : D√©tection d'objets et segmentation

---

## Glossaire

**Activation** : Fonction non-lin√©aire appliqu√©e apr√®s la convolution (ReLU, Sigmoid, Tanh).

**Batch Size** : Nombre d'√©chantillons trait√©s simultan√©ment.

**Bias (Biais)** : Terme constant ajout√© au r√©sultat de la convolution.

**Channel (Canal)** : Dimension de profondeur de l'image (RGB = 3 canaux).

**Convolution** : Op√©ration math√©matique appliquant un filtre sur une image.

**Feature Map** : R√©sultat de l'application d'un filtre sur l'input.

**Filter (Filtre)** : √âgalement appel√© kernel, matrice de poids apprise.

**Kernel** : Synonyme de filtre, matrice de convolution.

**Padding** : Ajout de pixels aux bords de l'image.

**Pooling** : Op√©ration de r√©duction de dimension (non utilis√©e dans les labs).

**Receptive Field** : R√©gion de l'input qui influence un neurone.

**Stride** : Pas de d√©placement du filtre.

**Weight Sharing** : Utilisation des m√™mes poids sur toute l'image.

---

## Auteur et Contact

**FILALI ANSARI Meryem**

√âtudiante en Deep Learning et Vision par Ordinateur  
Ann√©e acad√©mique 2024-2025

**Repository GitHub :** [LAB_LINEAR_AND_LOGISTIC_REG](https://github.com/meryemfilaliansari/LAB_LINEAR_AND_LOGISTIC_REG)

---

## Licence

Ce projet est √† usage √©ducatif et p√©dagogique dans le cadre universitaire.

---

## Changelog

**Version 1.0 (D√©cembre 2025)**
- Laboratoire 1 : CNN Fondamentaux avec convolution manuelle
- Laboratoire 2 : D√©tection de contours et applications pratiques
- Documentation compl√®te avec formules math√©matiques
- Visualisations p√©dagogiques d√©taill√©es

---

**Derni√®re mise √† jour :** D√©cembre 2025  
**Statut :** Complet et fonctionnel  
**Version Python :** 3.8+  
**Version TensorFlow :** 2.8+  
**Format :** Professionnel sans emojis ni ic√¥nes
