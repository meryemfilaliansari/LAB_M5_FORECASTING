{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä M5 Forecasting - Exploration, Visualisation & Mod√©lisation (RNN, LSTM, GRU)\n",
    "### Objectifs :\n",
    "1Ô∏è‚É£ Explorer les donn√©es afin de comprendre leur structure et leurs tendances g√©n√©rales.\n",
    "2Ô∏è‚É£ Visualiser l‚Äô√©volution des ventes.\n",
    "3Ô∏è‚É£ Utiliser les donn√©es disponibles pour entra√Æner des mod√®les RNN, LSTM et GRU afin de pr√©dire les ventes futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/M5_Forecasting/'\n",
    "sales = pd.read_csv(path + 'sales_train_evaluation.csv')\n",
    "calendar = pd.read_csv(path + 'calendar.csv')\n",
    "prices = pd.read_csv(path + 'sell_prices.csv')\n",
    "print('‚úÖ Donn√©es charg√©es avec succ√®s !')\n",
    "print('Sales shape:', sales.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Apercu du calendrier:')\n",
    "print(calendar.head())\n",
    "print('\\nApercu des prix:')\n",
    "print(prices.head())\n",
    "print('\\nNombre de produits uniques:', sales.shape[0])\n",
    "print('Nombre de jours de ventes:', sales.shape[1] - 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Apercu des donnees de ventes:')\n",
    "print(sales.head())\n",
    "print('\\nInformations sur les colonnes:')\n",
    "print(sales.info())\n",
    "print('\\nStatistiques descriptives:')\n",
    "print(sales.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des Donnees\n",
    "\n",
    "Analysons la structure des donnees avant de continuer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = sales.sample(1, random_state=42)['id'].values[0]\n",
    "ts = sales[sales['id'] == item_id].iloc[0, 6:].reset_index(drop=True)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(ts)\n",
    "plt.title(f'√âvolution des ventes pour {item_id}')\n",
    "plt.xlabel('Jour')\n",
    "plt.ylabel('Ventes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales = sales.iloc[:, 6:].sum(axis=0)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(total_sales.values, linewidth=1)\n",
    "plt.title('Evolution des Ventes Totales (Tous Produits)')\n",
    "plt.xlabel('Jour')\n",
    "plt.ylabel('Ventes Totales')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "print(f'Ventes totales moyennes par jour: {total_sales.mean():.2f}')\n",
    "print(f'Ventes totales max: {total_sales.max():.0f}')\n",
    "print(f'Ventes totales min: {total_sales.min():.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "for i in range(3):\n",
    "    item = sales.sample(1, random_state=i*10)['id'].values[0]\n",
    "    ts_sample = sales[sales['id'] == item].iloc[0, 6:].reset_index(drop=True)\n",
    "    axes[i].plot(ts_sample, linewidth=0.8)\n",
    "    axes[i].set_title(f'Serie temporelle: {item}')\n",
    "    axes[i].set_xlabel('Jour')\n",
    "    axes[i].set_ylabel('Ventes')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des Tendances\n",
    "\n",
    "Explorons plusieurs series temporelles pour comprendre les differents patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ts[-1000:].values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "SEQ_LEN = 30\n",
    "X, y = create_sequences(data_scaled, SEQ_LEN)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Forme des donnees apres extraction: {data.shape}')\n",
    "print(f'Nombre de sequences creees: {len(X)}')\n",
    "print(f'Taille de lensemble dentrainement: {len(X_train)}')\n",
    "print(f'Taille de lensemble de test: {len(X_test)}')\n",
    "print(f'Forme de X_train: {X_train.shape}')\n",
    "print(f'Forme de y_train: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation des Donnees pour les Modeles RNN\n",
    "\n",
    "Normalisation et creation des sequences temporelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type='RNN'):\n",
    "    model = Sequential()\n",
    "    if model_type == 'RNN':\n",
    "        model.add(SimpleRNN(50, activation='tanh', input_shape=(SEQ_LEN, 1)))\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(50, activation='tanh', input_shape=(SEQ_LEN, 1)))\n",
    "    elif model_type == 'GRU':\n",
    "        model.add(GRU(50, activation='tanh', input_shape=(SEQ_LEN, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32, verbose=0)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "    y_test_inv = scaler.inverse_transform(y_test)\n",
    "    mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    return model, history, mae, y_pred_inv, y_test_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction et Entrainement des Modeles\n",
    "\n",
    "Nous allons comparer trois architectures de reseaux de neurones recurrents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "histories = {}\n",
    "maes = {}\n",
    "for model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "    print(f'\n",
    "üöÄ Entra√Ænement du mod√®le {model_type}...')\n",
    "    model, history, mae, y_pred, y_true = train_model(model_type)\n",
    "    models[model_type] = model\n",
    "    histories[model_type] = history\n",
    "    maes[model_type] = mae\n",
    "    print(f'MAE ({model_type}): {mae:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "for model_type in histories.keys():\n",
    "    plt.plot(histories[model_type].history['mae'], label=f'{model_type} - Train')\n",
    "    plt.plot(histories[model_type].history['val_mae'], linestyle='--', label=f'{model_type} - Val')\n",
    "plt.title('Comparaison des MAE (entra√Ænement & validation)')\n",
    "plt.xlabel('√âpoque')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RESUME DES RESULTATS')\n",
    "print('='*70)\n",
    "print(f'\\nMeilleur modele selon MAE: {results_df.loc[results_df[\"MAE\"].idxmin(), \"Modele\"]}')\n",
    "print(f'MAE du meilleur modele: {results_df[\"MAE\"].min():.4f}')\n",
    "print(f'\\nMeilleur modele selon R2: {results_df.loc[results_df[\"R2\"].idxmax(), \"Modele\"]}')\n",
    "print(f'R2 du meilleur modele: {results_df[\"R2\"].max():.4f}')\n",
    "\n",
    "print('\\n\\nAMELIORATIONS POSSIBLES:')\n",
    "print('-' * 70)\n",
    "print('1. Augmenter le nombre de neurones (actuellement 50)')\n",
    "print('2. Ajouter des couches recurrentes supplementaires (modele plus profond)')\n",
    "print('3. Tester differentes longueurs de sequences (actuellement 30)')\n",
    "print('4. Utiliser Bidirectional LSTM/GRU')\n",
    "print('5. Ajouter du Dropout pour regularisation')\n",
    "print('6. Augmenter le nombre depoques dentrainement')\n",
    "print('7. Utiliser Early Stopping et Learning Rate Scheduling')\n",
    "print('8. Incorporer des features externes (calendrier, prix, promotions)')\n",
    "print('9. Essayer des architectures hybrides (CNN-LSTM)')\n",
    "print('10. Utiliser des techniques densemble (moyenne des predictions)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion et Recommandations\n",
    "\n",
    "Resumons les resultats et proposons des ameliorations possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Architecture du modele {model_type}:')\n",
    "    print(f'{\"=\"*60}')\n",
    "    models[model_type].summary()\n",
    "    print(f'\\nNombre total de parametres: {models[model_type].count_params():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture des Modeles\n",
    "\n",
    "Affichons les details de larchitecture de chaque modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "for model_type in histories.keys():\n",
    "    plt.plot(histories[model_type].history['loss'], label=f'{model_type} - Train Loss', linewidth=2)\n",
    "    plt.plot(histories[model_type].history['val_loss'], linestyle='--', label=f'{model_type} - Val Loss', linewidth=2)\n",
    "plt.title('Comparaison des Fonctions de Perte (MSE)')\n",
    "plt.xlabel('Epoque')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des Courbes dApprentissage\n",
    "\n",
    "Analysons levolution de la perte pendant lentrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(14, 12))\n",
    "for idx, model_type in enumerate(['RNN', 'LSTM', 'GRU']):\n",
    "    model = models[model_type]\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "    y_test_inv = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    residuals = y_test_inv - y_pred_inv\n",
    "    \n",
    "    axes[idx, 0].scatter(y_pred_inv, residuals, alpha=0.5, s=10)\n",
    "    axes[idx, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    axes[idx, 0].set_title(f'Residus vs Predictions ({model_type})')\n",
    "    axes[idx, 0].set_xlabel('Predictions')\n",
    "    axes[idx, 0].set_ylabel('Residus')\n",
    "    axes[idx, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[idx, 1].hist(residuals, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[idx, 1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "    axes[idx, 1].set_title(f'Distribution des Residus ({model_type})')\n",
    "    axes[idx, 1].set_xlabel('Residus')\n",
    "    axes[idx, 1].set_ylabel('Frequence')\n",
    "    axes[idx, 1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des Residus\n",
    "\n",
    "Analysons les erreurs de prediction pour comprendre les forces et faiblesses de chaque modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "metrics = ['MAE', 'RMSE', 'R2', 'MAPE']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    values = results_df[metric].values\n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "    bars = ax.bar(results_df['Modele'], values, color=colors, alpha=0.7)\n",
    "    ax.set_title(f'Comparaison: {metric}')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{value:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "results = []\n",
    "for model_type in ['RNN', 'LSTM', 'GRU']:\n",
    "    model = models[model_type]\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "    y_test_inv = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "    mape = mean_absolute_percentage_error(y_test_inv, y_pred_inv)\n",
    "    \n",
    "    results.append({\n",
    "        'Modele': model_type,\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print('\\nTableau Comparatif des Performances:')\n",
    "print(results_df.to_string(index=False))\n",
    "print(f'\\nMeilleur modele (MAE): {results_df.loc[results_df[\"MAE\"].idxmin(), \"Modele\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metriques de Performance Detaillees\n",
    "\n",
    "Calculons plusieurs metriques pour evaluer les modeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "for idx, model_type in enumerate(['RNN', 'LSTM', 'GRU']):\n",
    "    model = models[model_type]\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "    y_test_inv = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    axes[idx].plot(y_test_inv[:100], label='Valeurs Reelles', linewidth=2, alpha=0.7)\n",
    "    axes[idx].plot(y_pred_inv[:100], label='Predictions', linewidth=2, alpha=0.7)\n",
    "    axes[idx].set_title(f'Predictions du modele {model_type} (MAE: {maes[model_type]:.3f})')\n",
    "    axes[idx].set_xlabel('Temps')\n",
    "    axes[idx].set_ylabel('Ventes')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
